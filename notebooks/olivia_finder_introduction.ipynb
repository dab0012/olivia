{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olivia-Finder introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Previous requirements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make sure to have the necessary units installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.5.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.28.2)\n",
      "Requirement already satisfied: BeautifulSoup4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (4.12.0)\n",
      "Requirement already satisfied: colorama in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: selenium in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (4.8.2)\n",
      "Requirement already satisfied: webdriver-manager in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (3.8.5)\n",
      "Requirement already satisfied: sphinx in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (6.1.3)\n",
      "Requirement already satisfied: sphinx-autodoc-typehints in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.22)\n",
      "Requirement already satisfied: numpydoc in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.5.0)\n",
      "Collecting typing_extensions\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (1.24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->-r requirements.txt (line 3)) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests->-r requirements.txt (line 3)) (1.26.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.9/site-packages (from BeautifulSoup4->-r requirements.txt (line 4)) (2.4)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./.venv/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 6)) (0.10.2)\n",
      "Requirement already satisfied: trio~=0.17 in ./.venv/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 6)) (0.22.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.9/site-packages (from webdriver-manager->-r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.9/site-packages (from webdriver-manager->-r requirements.txt (line 7)) (23.0)\n",
      "Requirement already satisfied: imagesize>=1.3 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (1.4.1)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: Pygments>=2.13 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (2.14.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (6.1.0)\n",
      "Requirement already satisfied: docutils<0.20,>=0.18 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (0.19)\n",
      "Requirement already satisfied: babel>=2.9 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (2.12.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (0.7.13)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (1.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (2.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in ./.venv/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 8)) (1.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.9/site-packages (from importlib-metadata>=4.8->sphinx->-r requirements.txt (line 8)) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from Jinja2>=3.0->sphinx->-r requirements.txt (line 8)) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: outcome in ./.venv/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in ./.venv/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 6)) (22.2.0)\n",
      "Requirement already satisfied: sortedcontainers in ./.venv/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 6)) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in ./.venv/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 6)) (1.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in ./.venv/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./.venv/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./.venv/lib/python3.9/site-packages (from urllib3<1.27,>=1.21.1->requests->-r requirements.txt (line 3)) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./.venv/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->-r requirements.txt (line 6)) (0.14.0)\n",
      "Installing collected packages: typing_extensions\n",
      "Successfully installed typing_extensions-4.5.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/home/daniel_alonso/tfg/olivia-finder/notebooks/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating virtual atmosphere .venv ...\n",
      "/home/daniel_alonso/tfg/olivia-finder/notebooks/.venv/bin/python3\n"
     ]
    }
   ],
   "source": [
    "!source load_venv.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - DataSource"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class **DataSource** provides an interface for the obtaining of data from the different existing Packs managers.\n",
    "\n",
    "A datasource can implement classes:\n",
    "\n",
    "- **Scraper**, to obtain the data directly from the website of the package manager\n",
    "- **CSVNetwork**, to obtain the data from a CSV file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will instantize the desired implementation of data source class\n",
    "\n",
    "Below are some of its most relevant features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data obtaining via web scarping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first place we import the implementation of the data source we want, for this example we will use the Bioconductor Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "level must be an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39molivia_finder\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_source\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscrapers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbioconductor\u001b[39;00m \u001b[39mimport\u001b[39;00m BiocScraper\n\u001b[0;32m----> 2\u001b[0m bioc_scraper_ds \u001b[39m=\u001b[39m BiocScraper()\n",
      "File \u001b[0;32m~/tfg/olivia-finder/notebooks/olivia_finder/data_source/scrapers/bioconductor.py:64\u001b[0m, in \u001b[0;36mBiocScraper.__init__\u001b[0;34m(self, name, description, request_handler)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m, \n\u001b[1;32m     57\u001b[0m     name: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m NAME, \n\u001b[1;32m     58\u001b[0m     description: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m DESCRIPTION, \n\u001b[1;32m     59\u001b[0m     request_handler: Optional[RequestHandler] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \n\u001b[1;32m     60\u001b[0m ):\n\u001b[1;32m     61\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m    Constructor\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name, description, request_handler)\n",
      "File \u001b[0;32m~/tfg/olivia-finder/notebooks/olivia_finder/data_source/scraper.py:58\u001b[0m, in \u001b[0;36mScraper.__init__\u001b[0;34m(self, name, description, request_handler)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m# if request_handler is None build a generic RequestHandler\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m request_handler \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_handler \u001b[39m=\u001b[39m RequestHandler()\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_handler: request_handler\n",
      "File \u001b[0;32m~/tfg/olivia-finder/notebooks/olivia_finder/myrequests/request_handler.py:64\u001b[0m, in \u001b[0;36mRequestHandler.__init__\u001b[0;34m(self, proxy_handler, useragents_handler, max_retry, request_timeout, num_processes)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Constructor'''\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m# Check proxy handler\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy_handler \u001b[39m=\u001b[39m ProxyHandler() \u001b[39mif\u001b[39;00m proxy_handler \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m proxy_handler\n\u001b[1;32m     66\u001b[0m \u001b[39m# Check user agent handler\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39museragents_handler \u001b[39m=\u001b[39m UserAgentHandler() \u001b[39mif\u001b[39;00m useragents_handler \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m useragents_handler\n",
      "File \u001b[0;32m~/tfg/olivia-finder/notebooks/olivia_finder/myrequests/proxy_handler.py:60\u001b[0m, in \u001b[0;36mProxyHandler.__init__\u001b[0;34m(self, builders, proxy_max_uses)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m# Set proxy builders, if none, get default builders\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m builders \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:                                \n\u001b[0;32m---> 60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy_builders \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_available_builders()\n\u001b[1;32m     61\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[39m# Check if builders are valid\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m builder \u001b[39min\u001b[39;00m builders:\n\u001b[1;32m     64\u001b[0m         \u001b[39m# if any of the builders is not valid, ignore and continue with the next one\u001b[39;00m\n",
      "File \u001b[0;32m~/tfg/olivia-finder/notebooks/olivia_finder/myrequests/proxy_handler.py:173\u001b[0m, in \u001b[0;36mProxyHandler.__get_available_builders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m builder \u001b[39min\u001b[39;00m ProxyBuilder\u001b[39m.\u001b[39m__subclasses__():\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m     \u001b[39m# append builder object\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     builders\u001b[39m.\u001b[39mappend(builder())\n\u001b[0;32m--> 173\u001b[0m     MyLogger\u001b[39m.\u001b[39;49mlog(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAdded \u001b[39;49m\u001b[39m{\u001b[39;49;00mbuilder\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m to proxy builders\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    175\u001b[0m \u001b[39mreturn\u001b[39;00m builders\n",
      "File \u001b[0;32m~/tfg/olivia-finder/notebooks/olivia_finder/util/logger.py:127\u001b[0m, in \u001b[0;36mMyLogger.log\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    124\u001b[0m _self \u001b[39m=\u001b[39m MyLogger\u001b[39m.\u001b[39mget_instance()\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m _self\u001b[39m.\u001b[39mstatus:\n\u001b[1;32m    126\u001b[0m     \u001b[39m# Log the text\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     logging\u001b[39m.\u001b[39;49mgetLogger()\u001b[39m.\u001b[39;49mlog(_self\u001b[39m.\u001b[39;49mlevel, text)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/logging/__init__.py:1508\u001b[0m, in \u001b[0;36mLogger.log\u001b[0;34m(self, level, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(level, \u001b[39mint\u001b[39m):\n\u001b[1;32m   1507\u001b[0m     \u001b[39mif\u001b[39;00m raiseExceptions:\n\u001b[0;32m-> 1508\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlevel must be an integer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1509\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1510\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: level must be an integer"
     ]
    }
   ],
   "source": [
    "from olivia_finder.data_source.scrapers.bioconductor import BiocScraper\n",
    "bioc_scraper_ds = BiocScraper()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show relevant information about the data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Bioconductor\n",
      "Description: Scraper class implementation for the Bioconductor package network\n"
     ]
    }
   ],
   "source": [
    "print(bioc_scraper_ds.get_info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list with the name of the packages obtained from this source\n",
    "\n",
    "Specifically, the Biic Scraper class gets the list of packages from the url:\n",
    "\n",
    "-   https://bioconductor.org/packages/release/BiocViews.html#___Software"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each specific implementation of a Scraper must manage this process on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABSSeq',\n",
       " 'ABarray',\n",
       " 'ACE',\n",
       " 'ACME',\n",
       " 'ADAM',\n",
       " 'ADAMgui',\n",
       " 'ADImpute',\n",
       " 'ADaCGH2',\n",
       " 'AGDEX',\n",
       " 'AIMS']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_list = bioc_scraper_ds.obtain_package_names()\n",
    "package_list[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the data from a specific package, for example the **`DeepBlueR`** package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'DeepBlueR',\n",
       " 'version': '1.24.1',\n",
       " 'dependencies': [{'name': 'R', 'version': '>= 3.3'},\n",
       "  {'name': 'XML', 'version': ''},\n",
       "  {'name': 'RCurl', 'version': ''},\n",
       "  {'name': 'GenomicRanges', 'version': ''},\n",
       "  {'name': 'data.table', 'version': ''},\n",
       "  {'name': 'stringr', 'version': ''},\n",
       "  {'name': 'diffr', 'version': ''},\n",
       "  {'name': 'dplyr', 'version': ''},\n",
       "  {'name': 'methods', 'version': ''},\n",
       "  {'name': 'rjson', 'version': ''},\n",
       "  {'name': 'utils', 'version': ''},\n",
       "  {'name': 'R.utils', 'version': ''},\n",
       "  {'name': 'foreach', 'version': ''},\n",
       "  {'name': 'withr', 'version': ''},\n",
       "  {'name': 'rtracklayer', 'version': ''},\n",
       "  {'name': 'GenomeInfoDb', 'version': ''},\n",
       "  {'name': 'settings', 'version': ''},\n",
       "  {'name': 'filehash', 'version': ''}],\n",
       " 'url': 'https://www.bioconductor.org/packages/release/bioc/html/DeepBlueR.html'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepbluer = bioc_scraper_ds.obtain_package_data(\"DeepBlueR\")\n",
    "deepbluer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful with the sensitivity to **caps**, if the package has not been found, an **ScraperError** exception is raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 20:20:28 [   DEBUG] Scraping package deepbluer (logger.py:96)\n",
      "2023-03-14 20:20:28 [   DEBUG] Getting next proxy (logger.py:96)\n",
      "2023-03-14 20:20:28 [   DEBUG] Proxy list rotated, using 202.166.164.115:5678, next will be 177.125.166.218:4145 (logger.py:96)\n",
      "2023-03-14 20:20:28 [   DEBUG] Using proxy: {'http': 'http://202.166.164.115:5678'} (logger.py:96)\n",
      "2023-03-14 20:20:28 [   DEBUG] Getting next useragent (logger.py:96)\n",
      "2023-03-14 20:20:28 [   DEBUG] Using user agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.125 Safari/537.36 (logger.py:96)\n",
      "2023-03-14 20:20:28 [   DEBUG] Starting new HTTPS connection (1): www.bioconductor.org:443 (connectionpool.py:1003)\n",
      "2023-03-14 20:20:29 [   DEBUG] https://www.bioconductor.org:443 \"GET /packages/release/bioc/html/deepbluer.html HTTP/1.1\" 404 6873 (connectionpool.py:456)\n",
      "2023-03-14 20:20:29 [   DEBUG] Response status code: 404 (logger.py:96)\n",
      "2023-03-14 20:20:29 [   DEBUG] ScraperError: Package deepbluer not found\n",
      "super (logger.py:96)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScraperError: Package deepbluer not found\n",
      "super\n"
     ]
    }
   ],
   "source": [
    "from olivia_finder.util.logger import UtilLogger\n",
    "UtilLogger.enable_logger()\n",
    "try:\n",
    "    deepbluer2 = bioc_scraper_ds.obtain_package_data(\"deepbluer\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the data from a list of package names using the function:\n",
    "-   ```python\n",
    "    obtain_packages_data(list[str])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'ABSSeq',\n",
       "  'version': '1.52.0',\n",
       "  'dependencies': [{'name': 'R', 'version': '>= 2.10'},\n",
       "   {'name': 'methods', 'version': ''},\n",
       "   {'name': 'locfit', 'version': ''},\n",
       "   {'name': 'limma', 'version': ''}],\n",
       "  'url': 'https://www.bioconductor.org/packages/release/bioc/html/ABSSeq.html'},\n",
       " {'name': 'ABarray',\n",
       "  'version': '1.66.0',\n",
       "  'dependencies': [{'name': 'Biobase', 'version': ''},\n",
       "   {'name': 'graphics', 'version': ''},\n",
       "   {'name': 'grDevices', 'version': ''},\n",
       "   {'name': 'methods', 'version': ''},\n",
       "   {'name': 'multtest', 'version': ''},\n",
       "   {'name': 'stats', 'version': ''},\n",
       "   {'name': 'tcltk', 'version': ''},\n",
       "   {'name': 'utils', 'version': ''}],\n",
       "  'url': 'https://www.bioconductor.org/packages/release/bioc/html/ABarray.html'},\n",
       " {'name': 'ACE',\n",
       "  'version': '1.16.0',\n",
       "  'dependencies': [{'name': 'R', 'version': '>= 3.4'},\n",
       "   {'name': 'Biobase', 'version': ''},\n",
       "   {'name': 'QDNAseq', 'version': ''},\n",
       "   {'name': 'ggplot2', 'version': ''},\n",
       "   {'name': 'grid', 'version': ''},\n",
       "   {'name': 'stats', 'version': ''},\n",
       "   {'name': 'utils', 'version': ''},\n",
       "   {'name': 'methods', 'version': ''},\n",
       "   {'name': 'grDevices', 'version': ''},\n",
       "   {'name': 'GenomicRanges', 'version': ''}],\n",
       "  'url': 'https://www.bioconductor.org/packages/release/bioc/html/ACE.html'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkgs_data, not_found = bioc_scraper_ds.obtain_packages_data(package_list[:3])\n",
    "pkgs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package: ABSSeq (1.52.0)\n",
      "-   Dependency: R >= 2.10\n",
      "-   Dependency: methods \n",
      "-   Dependency: locfit \n",
      "-   Dependency: limma \n",
      "Package: ABarray (1.66.0)\n",
      "-   Dependency: Biobase \n",
      "-   Dependency: graphics \n",
      "-   Dependency: grDevices \n",
      "-   Dependency: methods \n",
      "-   Dependency: multtest \n",
      "-   Dependency: stats \n",
      "-   Dependency: tcltk \n",
      "-   Dependency: utils \n",
      "Package: ACE (1.16.0)\n",
      "-   Dependency: R >= 3.4\n",
      "-   Dependency: Biobase \n",
      "-   Dependency: QDNAseq \n",
      "-   Dependency: ggplot2 \n",
      "-   Dependency: grid \n",
      "-   Dependency: stats \n",
      "-   Dependency: utils \n",
      "-   Dependency: methods \n",
      "-   Dependency: grDevices \n",
      "-   Dependency: GenomicRanges \n"
     ]
    }
   ],
   "source": [
    "for p in pkgs_data:\n",
    "    print(f'Package: {p[\"name\"]} ({p[\"version\"]})')\n",
    "\n",
    "    for d in p[\"dependencies\"]:\n",
    "        print(f'-   Dependency: {d[\"name\"]} {d[\"version\"]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages not found appear as the second object of the tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deepbluer']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkgs_data, not_found = bioc_scraper_ds.obtain_packages_data([\"deepbluer\", \"DeepBlueR\"])\n",
    "not_found"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data obtaining from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olivia_finder.csv_network import CSVNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network\n",
    "bioc_csv_ds = CSVNetwork(\"Bioconductor\", \"Bioconductor as a CSV file\")\n",
    "bioc_csv_ds.load_data(\n",
    "    file_path=\"results/csv_datasets/bioconductor_adjlist_scraping.csv\", \n",
    "    dependent_field=\"name\", dependency_field=\"dependency\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABSSeq',\n",
       " 'ABarray',\n",
       " 'ACE',\n",
       " 'ACME',\n",
       " 'ADAM',\n",
       " 'ADAMgui',\n",
       " 'ADImpute',\n",
       " 'ADaCGH2',\n",
       " 'AGDEX',\n",
       " 'AIMS']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_list = bioc_csv_ds.obtain_package_names()\n",
    "package_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'DeepBlueR',\n",
       " 'version': None,\n",
       " 'url': None,\n",
       " 'dependencies': [{'name': 'R', 'version': '>= 3.3'},\n",
       "  {'name': 'XML', 'version': nan},\n",
       "  {'name': 'RCurl', 'version': nan},\n",
       "  {'name': 'GenomicRanges', 'version': nan},\n",
       "  {'name': 'data.table', 'version': nan},\n",
       "  {'name': 'stringr', 'version': nan},\n",
       "  {'name': 'diffr', 'version': nan},\n",
       "  {'name': 'dplyr', 'version': nan},\n",
       "  {'name': 'methods', 'version': nan},\n",
       "  {'name': 'rjson', 'version': nan},\n",
       "  {'name': 'utils', 'version': nan},\n",
       "  {'name': 'R.utils', 'version': nan},\n",
       "  {'name': 'foreach', 'version': nan},\n",
       "  {'name': 'withr', 'version': nan},\n",
       "  {'name': 'rtracklayer', 'version': nan},\n",
       "  {'name': 'GenomeInfoDb', 'version': nan},\n",
       "  {'name': 'settings', 'version': nan},\n",
       "  {'name': 'filehash', 'version': nan}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepbluer = bioc_csv_ds.obtain_package_data(\"DeepBlueR\")\n",
    "deepbluer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 762.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'ABSSeq',\n",
       "  'version': None,\n",
       "  'url': None,\n",
       "  'dependencies': [{'name': 'R', 'version': '>= 2.10'},\n",
       "   {'name': 'methods', 'version': nan},\n",
       "   {'name': 'locfit', 'version': nan},\n",
       "   {'name': 'limma', 'version': nan}]},\n",
       " {'name': 'ABarray',\n",
       "  'version': None,\n",
       "  'url': None,\n",
       "  'dependencies': [{'name': 'Biobase', 'version': nan},\n",
       "   {'name': 'graphics', 'version': nan},\n",
       "   {'name': 'grDevices', 'version': nan},\n",
       "   {'name': 'methods', 'version': nan},\n",
       "   {'name': 'multtest', 'version': nan},\n",
       "   {'name': 'stats', 'version': nan},\n",
       "   {'name': 'tcltk', 'version': nan},\n",
       "   {'name': 'utils', 'version': nan}]},\n",
       " {'name': 'ACE',\n",
       "  'version': None,\n",
       "  'url': None,\n",
       "  'dependencies': [{'name': 'R', 'version': '>= 3.4'},\n",
       "   {'name': 'Biobase', 'version': nan},\n",
       "   {'name': 'QDNAseq', 'version': nan},\n",
       "   {'name': 'ggplot2', 'version': nan},\n",
       "   {'name': 'grid', 'version': nan},\n",
       "   {'name': 'stats', 'version': nan},\n",
       "   {'name': 'utils', 'version': nan},\n",
       "   {'name': 'methods', 'version': nan},\n",
       "   {'name': 'grDevices', 'version': nan},\n",
       "   {'name': 'GenomicRanges', 'version': nan}]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packages = bioc_csv_ds.obtain_packages_data(package_list[:3])\n",
    "packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Initialization of a package manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olivia_finder.package_manager import PackageManager"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declare the class**\n",
    "\n",
    "Initialize the packagemanager class with the implementation of the scraper we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes exactly one argument (the instance to initialize)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39molivia_finder\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_source\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscrapers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpypi\u001b[39;00m \u001b[39mimport\u001b[39;00m PypiScraper\n\u001b[0;32m----> 2\u001b[0m pypi_scraper_pm \u001b[39m=\u001b[39m PackageManager(PypiScraper())\n",
      "File \u001b[0;32m~/tfg/olivia-finder/notebooks/olivia_finder/data_source/scrapers/pypi.py:48\u001b[0m, in \u001b[0;36mPypiScraper.__init__\u001b[0;34m(self, request_handler)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, request_handler: RequestHandler \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     44\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m    Constructor\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mNAME, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mDESCRIPTION, request_handler)\n",
      "File \u001b[0;32m~/tfg/olivia-finder/notebooks/olivia_finder/data_source/scraper.py:53\u001b[0m, in \u001b[0;36mScraper.__init__\u001b[0;34m(self, name, description, request_handler)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mConstructor of the class\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m# Call the super constructor\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(name, description)\n\u001b[1;32m     55\u001b[0m \u001b[39m# if request_handler is None build a generic RequestHandler\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m request_handler \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes exactly one argument (the instance to initialize)"
     ]
    }
   ],
   "source": [
    "from olivia_finder.data_source.scrapers.pypi import PypiScraper\n",
    "pypi_scraper_pm = PackageManager(PypiScraper())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or init the class from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped CRAN packages: 18195\n"
     ]
    }
   ],
   "source": [
    "cran_scraped_csv_pm = PackageManager.load_csv_adjlist(\n",
    "    \"results/csv_datasets/cran_full_adjlist.csv\", default_format=True\n",
    ")\n",
    "\n",
    "print(f'Scraped CRAN packages: {len(cran_scraped_csv_pm.data_source.obtain_package_names())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries.io CRAN packages: 15522\n"
     ]
    }
   ],
   "source": [
    "cran_librariesio_csv_pm = PackageManager.load_csv_adjlist(\n",
    "    \"results/csv_datasets/cran_librariesio_dependencies.csv\",\n",
    "    dependent_field=\"Project Name\",\n",
    "    dependency_field=\"Dependency Name\",\n",
    "    version_field=\"Version Number\",\n",
    ")\n",
    "print(f'Libraries.io CRAN packages: {len(cran_librariesio_csv_pm.data_source.obtain_package_names())}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a package from package manager**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package:\n",
      "  name: networkx\n",
      "  version: 3.0\n",
      "  url: https://pypi.org/project/networkx/\n",
      "  dependencies:\n",
      "    numpy:(>=1.20)\n",
      "    scipy:(>=1.8)\n",
      "    matplotlib:(>=3.4)\n",
      "    pandas:(>=1.3)\n",
      "    pre-commit:(>=2.20)\n",
      "    mypy:(>=0.991)\n",
      "    sphinx:(==5.2.3)\n",
      "    pydata-sphinx-theme:(>=0.11)\n",
      "    sphinx-gallery:(>=0.11)\n",
      "    numpydoc:(>=1.5)\n",
      "    pillow:(>=9.2)\n",
      "    nb2plots:(>=0.6)\n",
      "    texext:(>=0.6.7)\n",
      "    lxml:(>=4.6)\n",
      "    pygraphviz:(>=1.10)\n",
      "    pydot:(>=1.4.2)\n",
      "    sympy:(>=1.10)\n",
      "    pytest:(>=7.2)\n",
      "    pytest-cov:(>=4.0)\n",
      "    codecov:(>=2.1)\n"
     ]
    }
   ],
   "source": [
    "networkx = pypi_scraper_pm.obtain_package(\"networkx\")\n",
    "networkx.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package:\n",
      "  name: A3\n",
      "  version: 1.0.0\n",
      "  url: https://cran.r-project.org/package=A3\n",
      "  dependencies:\n",
      "    R:≥ 2.15.0\n",
      "    xtable:nan\n",
      "    pbapply:nan\n"
     ]
    }
   ],
   "source": [
    "cran_scraped_csv_pm.obtain_package(\"A3\").print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get packages from a list of package names**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webscraping-based implementation obtains the data manager website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<olivia_finder.package.Package at 0x7f4d8769afd0>,\n",
       " <olivia_finder.package.Package at 0x7f4d876aec10>,\n",
       " <olivia_finder.package.Package at 0x7f4d876aefa0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packages = pypi_scraper_pm.obtain_packages([\"networkx\", \"numpy\", \"pandas\"])\n",
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package:\n",
      "  name: pandas\n",
      "  version: 1.5.3\n",
      "  url: https://pypi.org/project/pandas/\n",
      "  dependencies:\n",
      "    python-dateutil:(>=2.8.1)\n",
      "    pytz:(>=2020.1)\n",
      "    numpy:(>=1.23.2)\n",
      "    hypothesis:(>=5.5.3)\n",
      "    pytest:(>=6.0)\n",
      "    pytest-xdist:(>=1.31)\n"
     ]
    }
   ],
   "source": [
    "packages[2].print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV file-based implementation obtains file data from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 158.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package:\n",
      "  name: A3\n",
      "  version: 1.0.0\n",
      "  url: https://cran.r-project.org/package=A3\n",
      "  dependencies:\n",
      "    R:≥ 2.15.0\n",
      "    xtable:nan\n",
      "    pbapply:nan\n",
      "Package:\n",
      "  name: pbapply\n",
      "  version: 1.7-0\n",
      "  url: https://cran.r-project.org/package=pbapply\n",
      "  dependencies:\n",
      "    R:≥ 3.2.0\n",
      "    parallel:nan\n",
      "Package:\n",
      "  name: xtable\n",
      "  version: 1.8-4\n",
      "  url: https://cran.r-project.org/package=xtable\n",
      "  dependencies:\n",
      "    R:≥ 2.10.0\n",
      "    stats:nan\n",
      "    utils:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cran_packages = cran_scraped_csv_pm.obtain_packages([\"A3\", \"pbapply\", \"xtable\"])\n",
    "for p in cran_packages:\n",
    "    p.print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all packages from a package manager**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:***\n",
    "\n",
    "The functionality of storing packages in the PackageManager object has been implemented\n",
    "\n",
    "-   Can be activated by flag\n",
    "\n",
    "    ```python\n",
    "    extend=True\n",
    "    ```\n",
    "\n",
    "The functionality of showing the progress of obtaining packages has been implemented\n",
    "\n",
    "-   Can be activated by flag\n",
    "\n",
    "    ```python\n",
    "    show_progress=True\n",
    "    ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the packages from a package manager can take a while, so it is recommended to save the data to a CSV file for later use.\n",
    "\n",
    "We can see that the execution time for half a million packages (Pypi) is around 7 hours.\n",
    "In the case of Bioconductor, to obtain the 2000 packages it contains, the execution time is around 4 minutes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   From **Spraper** data source implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 66423/438514 [1:14:50<6:40:39, 15.48it/s] "
     ]
    }
   ],
   "source": [
    "pypi_packages = pypi_scraper_pm.obtain_packages(extend=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2183/2183 [03:47<00:00,  9.59it/s]\n"
     ]
    }
   ],
   "source": [
    "bioc_scraper_pm = PackageManager(BiocScraper())\n",
    "bioconductor_packages = bioc_scraper_pm.obtain_packages(extend=True, show_progress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   From **CSVNetwork** data source implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18195/18195 [02:04<00:00, 145.67it/s]\n"
     ]
    }
   ],
   "source": [
    "cran_packages = cran_scraped_csv_pm.obtain_packages(extend=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package:\n",
      "  name: A3\n",
      "  version: 1.0.0\n",
      "  url: https://cran.r-project.org/package=A3\n",
      "  dependencies:\n",
      "    R:≥ 2.15.0\n",
      "    xtable:nan\n",
      "    pbapply:nan\n"
     ]
    }
   ],
   "source": [
    "cran_scraped_csv_pm.obtain_package(\"A3\").print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package:\n",
      "  name: A3\n",
      "  version: 1.0.0\n",
      "  url: None\n",
      "  dependencies:\n",
      "    R\n",
      "    randomForest\n"
     ]
    }
   ],
   "source": [
    "cran_librariesio_csv_pm.obtain_package(\"A3\").print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen there is inconsistency among the different data sources, it is recommended to use the most up-to-date source"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data persistence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functionality of saving the PackageManager object in disk and loading of it has also been implemented, in order to maintain persistence and not repeat processes such as WebScraping."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the PackageManager object**\n",
    "\n",
    "We can save the object through the `save` function\n",
    "\n",
    "The file extension is irrelevant since it is a binary serialization, but by agreement the extension has been chosen **.olvpm** \"to identify the PackageManager files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cran_scraped_csv_pm.save(\"results/package_managers/cran.olvpm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the PackageManager object**\n",
    "\n",
    "We can load the PackageManager object through the static method\n",
    "\n",
    "```python \n",
    "    PackageManager.load(path:str)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package:\n",
      "  name: A3\n",
      "  version: 1.0.0\n",
      "  url: https://cran.r-project.org/package=A3\n",
      "  dependencies:\n",
      "    R:≥ 2.15.0\n",
      "    xtable:nan\n",
      "    pbapply:nan\n"
     ]
    }
   ],
   "source": [
    "cran_loaded_csv_pm = PackageManager.load(\"results/package_managers/cran.olvpm\")\n",
    "cran_loaded_csv_pm.packages[\"A3\"].print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export the CSV format**\n",
    "\n",
    "We can export the data of the packages to a CSV, with a structure similar to that of the data of Libraries.\n",
    "\n",
    "We can use the following function to generate a Pandas Dataframe and then write the file as Dis CSV\n",
    "\n",
    "-   \n",
    "    ```python\n",
    "    pandas_df = package_manager.export_full_adjlist()\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "      <th>url</th>\n",
       "      <th>dependency</th>\n",
       "      <th>dependency_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>https://cran.r-project.org/package=A3</td>\n",
       "      <td>R</td>\n",
       "      <td>≥ 2.15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>https://cran.r-project.org/package=A3</td>\n",
       "      <td>xtable</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>https://cran.r-project.org/package=A3</td>\n",
       "      <td>pbapply</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AATtools</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>https://cran.r-project.org/package=AATtools</td>\n",
       "      <td>R</td>\n",
       "      <td>≥ 3.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AATtools</td>\n",
       "      <td>0.0.2</td>\n",
       "      <td>https://cran.r-project.org/package=AATtools</td>\n",
       "      <td>magrittr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name version                                          url dependency  \\\n",
       "0        A3   1.0.0        https://cran.r-project.org/package=A3          R   \n",
       "1        A3   1.0.0        https://cran.r-project.org/package=A3     xtable   \n",
       "2        A3   1.0.0        https://cran.r-project.org/package=A3    pbapply   \n",
       "3  AATtools   0.0.2  https://cran.r-project.org/package=AATtools          R   \n",
       "4  AATtools   0.0.2  https://cran.r-project.org/package=AATtools   magrittr   \n",
       "\n",
       "  dependency_version  \n",
       "0           ≥ 2.15.0  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3            ≥ 3.6.0  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the package manager as a adjacency list\n",
    "cran_df = cran_loaded_csv_pm.export_full_adjlist()\n",
    "cran_df.to_csv(\"results/csv_datasets/cran_full_adjlist.csv\", index=False)\n",
    "cran_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
