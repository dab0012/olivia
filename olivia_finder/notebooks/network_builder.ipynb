{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olivia network builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../olivia/')\n",
    " \n",
    "from olivia.model import OliviaNetwork"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def add_chunk(\n",
    "    df, G, dependent_field, dependency_field,\n",
    "    filter_field=None,\n",
    "    filter_value=None\n",
    "):\n",
    "    \"\"\" Utility method for build_dependency_network\"\"\"\n",
    "\n",
    "    if filter_field:\n",
    "        filtered = df[df[filter_field] == filter_value]\n",
    "    else:\n",
    "        filtered = df\n",
    "\n",
    "    links = [(dependency, dependent) for (dependency, dependent) in zip(filtered[dependency_field], filtered[dependent_field])]\n",
    "    G.add_edges_from(links)\n",
    "    return G\n",
    "\n",
    "\n",
    "def build_dependency_network(input_file,\n",
    "                             output_file,\n",
    "                             chunk_size,\n",
    "                             dependent_field='Project Name',\n",
    "                             dependency_field='Dependency Name',\n",
    "                             filter_field=None,\n",
    "                             filter_value=None,\n",
    "                             verbose=True):\n",
    "    \"\"\"\n",
    "    Builds a dependency network from a file with package dependencies information\n",
    "\n",
    "    Reads from a CSV file and writes to a txt file with adjacency lists\n",
    "    corresponding to network model. Compression methods are inferred from file\n",
    "    extension (.gz and .bz2 are supported from NetworkX IO methods)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        Path to csv file with dependencies information\n",
    "    output_file : str\n",
    "        Path to write resulting network file\n",
    "    chunk_size : int\n",
    "        Amount of lines to be read at once from input_file in batch  processing.\n",
    "    dependent_field : str\n",
    "        DataFrame column Id for the dependent package\n",
    "    dependency_field : str\n",
    "        Dataframe column Id for the dependency package\n",
    "    filter_field : str, optional\n",
    "        If not None, only add records where filter_field equals filter_value\n",
    "    filter_value : str, optional\n",
    "        If not None, only add records where filter_field equals filter_value\n",
    "    verbose: bool, optional\n",
    "        If True, processing information is written to standard output.\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Print only if verbose\n",
    "    vprint = print if verbose else lambda *a, **k: None\n",
    "    process = psutil.Process(os.getpid())\n",
    "    vprint(\"Using process \", process)\n",
    "    t = time()\n",
    "    try:\n",
    "        vprint(f'Opening \"{input_file}\"... ', end='')\n",
    "        # Obtain reader iterator\n",
    "        reader = pd.read_csv(input_file, chunksize=chunk_size)\n",
    "        vprint('OK')\n",
    "        vprint('Initializing graph... ', end='')\n",
    "        # New NetworkX directed Graph\n",
    "        G = nx.DiGraph()\n",
    "        vprint('OK')\n",
    "        for i, chunk in enumerate(reader):\n",
    "            # Add dependencies from chunk to G\n",
    "            add_chunk(\n",
    "                chunk, \n",
    "                G,\n",
    "                dependent_field=dependent_field,\n",
    "                dependency_field=dependency_field,\n",
    "                filter_field=filter_field,\n",
    "                filter_value=filter_value\n",
    "            )\n",
    "            vprint(f'{round(i*chunk_size/1e6,1)}M lines | {len(G)} nodes,{len(G.edges)} deps. ({int(time()-t)}s) {round(process.memory_info().rss/1e6,1)}Mb ')\n",
    "        vprint('Done reading file')\n",
    "        vprint(f'Saving network as \"{output_file}\"... ', end='')\n",
    "        nx.write_adjlist(G, output_file)\n",
    "        vprint('OK')\n",
    "    except Exception as e:\n",
    "        print('\\n', e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using process  psutil.Process(pid=26687, name='python', status='running', started='10:01:51')\n",
      "Opening \"results/csv_datasets/bioconductor/bioconductor_adjlist_scraping.csv\"... OK\n",
      "Initializing graph... OK\n",
      "0.0M lines | 3509 nodes,28320 deps. (0s) 182.1Mb \n",
      "Done reading file\n",
      "Saving network as \"results/network_models/bioconductor_adjlist_scraping.bz2\"... OK\n",
      "Reading dependencies file...\n",
      "Building Olivia Model\n",
      "     Finding strongly connected components (SCCs)...\n",
      "     Building condensation network...\n",
      "     Adding structural meta-data...\n",
      "     Done\n"
     ]
    }
   ],
   "source": [
    "# Build Bioconductor network with scraping data\n",
    "build_dependency_network(\n",
    "    input_file='results/csv_datasets/bioconductor/bioconductor_adjlist_scraping.csv',\n",
    "    output_file='results/network_models/bioconductor_adjlist_scraping.bz2',\n",
    "    chunk_size=int(1e6),\n",
    "    dependent_field=\"name\",\n",
    "    dependency_field=\"dependency\"\n",
    ")\n",
    "\n",
    "# Build olivia model from network\n",
    "on = OliviaNetwork()\n",
    "on.build_model('results/network_models/bioconductor_adjlist_scraping.bz2')\n",
    "on.save('results/olivia_prebuilts/bioconductor.olv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using process  psutil.Process(pid=26687, name='python', status='running', started='10:01:51')\n",
      "Opening \"results/csv_datasets/cran/cran_adjlist_scraping.csv\"... OK\n",
      "Initializing graph... OK\n",
      "0.0M lines | 18671 nodes,113273 deps. (0s) 218.5Mb \n",
      "Done reading file\n",
      "Saving network as \"results/network_models/cran_adjlist_scraping.bz2\"... OK\n",
      "Reading dependencies file...\n",
      "Building Olivia Model\n",
      "     Finding strongly connected components (SCCs)...\n",
      "     Building condensation network...\n",
      "     Adding structural meta-data...\n",
      "     Done\n"
     ]
    }
   ],
   "source": [
    "# Build CRAN network with scraping data\n",
    "build_dependency_network(\n",
    "    input_file='results/csv_datasets/cran/cran_adjlist_scraping.csv',\n",
    "    output_file='results/network_models/cran_adjlist_scraping.bz2',\n",
    "    chunk_size=1e6,\n",
    "    dependent_field=\"name\",\n",
    "    dependency_field=\"dependency\"\n",
    ")\n",
    "\n",
    "# Build olivia model from network\n",
    "on = OliviaNetwork()\n",
    "on.build_model('results/network_models/cran_adjlist_scraping.bz2')\n",
    "on.save('results/olivia_prebuilts/cran.olv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using process  psutil.Process(pid=26687, name='python', status='running', started='10:01:51')\n",
      "Opening \"results/csv_datasets/pypi/pypi_adjlist_scraping.csv\"... OK\n",
      "Initializing graph... OK\n",
      "0.0M lines | 214469 nodes,933955 deps. (6s) 799.0Mb \n",
      "Done reading file\n",
      "Saving network as \"results/network_models/pypi_adjlist_scraping.bz2\"... OK\n",
      "Reading dependencies file...\n",
      "Building Olivia Model\n",
      "     Finding strongly connected components (SCCs)...\n",
      "     Building condensation network...\n",
      "     Adding structural meta-data...\n",
      "     Done\n"
     ]
    }
   ],
   "source": [
    "# Building PyPI network with scraping data\n",
    "build_dependency_network(\n",
    "    input_file='results/csv_datasets/pypi/pypi_adjlist_scraping.csv',\n",
    "    output_file='results/network_models/pypi_adjlist_scraping.bz2',\n",
    "    chunk_size=1e6,\n",
    "    dependent_field=\"name\",\n",
    "    dependency_field=\"dependency\"\n",
    ")\n",
    "\n",
    "# Build olivia model from network\n",
    "on = OliviaNetwork()\n",
    "on.build_model('results/network_models/pypi_adjlist_scraping.bz2')\n",
    "on.save('results/olivia_prebuilts/pypi.olv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
